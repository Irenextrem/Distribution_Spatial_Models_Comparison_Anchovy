---
title: "Modelos para compilar"
author: "Irene Extremera Serrano"
date: "10/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, warning = FALSE, error = FALSE, message = FALSE, comment = " ")
```

````{r, warning=FALSE, message=FALSE,include=FALSE }
library(sp) #Tabajar con objetos de tipo espacial
library(rgdal) #Para que funcione sdmpredictors
library(carData)
library(car)
library(nlme)
library(gstat)
library(sf)
library(spData)
library(spdep)
library(lattice)
library(survival)
library(Formula)
library(ggplot2)
library(Hmisc)
library(raster) #Para poder trabajar con objetos tipo raster
library(leaflet)
library(GGally)
library(maptools)
library(corrplot)
library(rgeos)
library(maptools) #Cargar mapas
library(dismo) #Para poder trabajar con bioclim
library(sdmpredictors) #Para descargarme las variables ambientales
library(PresenceAbsence)
library(rJava)
library(randomForest)
library(INLA) #Para trabajar con INLA
library(Matrix)
library(parallel)
library(foreach)
library(dotCall64)
library(grid)
library(spam)
library(fields)
```

```{r,include=FALSE}
setwd("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Rmd")
# Descargo el mapa del mundo
data(wrld_simpl) #Cargo el mapa del mundo
```


```{r,include=FALSE}
# Datos
data <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/Anchoas_Aqua.csv',TRUE,",")
data<- data[-1]

# Solo uso bathy como covariable hasta que seleccione las demás
bathy1 <- (list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/bathy", full.names=T, pattern=".tif")) #Cargo bathy que lo he metido en una carpeta aparte
predictors <- stack(bathy1)
names(predictors) <- c("bathy")
predictors2 <- scale(predictors)

# Con todas las covariables para calcular las pseudoausencias
files <- (list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores", full.names=T, pattern=".tif")) 
predictorss <- stack(files)
names(predictorss) <- c("bathy","chlomean","ppmean","odismean","salinity","tempmean")
predictors3 <- scale(predictorss)

# Necesito este objeto con el que he creado la base de datos sdmdata.Son coordenadas aleatorias en las cuales puede o no haber presencia de la especie. La semilla es la misma.
set.seed(141592) 
backgr <- randomPoints(predictors3, 1000) 
```


##################################
##### --- Ajuste modelos --- #####
##################################

# BIOCLIM

```{r}
# Hago el modelo de BIOCLIM
bc.model <- bioclim(x = predictors2, p = data)
bc.model
```


```{r}
# FUNCIÓN DEFINITIVA DEFINITIVÍSIMA MILENARIA XTREM para BIOCLIM.
# Esta función sirve para hacer una cross validation y obtener así los distintos índices que me interesan

fddmx <- function(coordenadas, predictores,background){

      group <- kfold(coordenadas, 5)

      pres_train <- coordenadas[group != 1, ] #Las que no sean 1
      pres_test <- coordenadas[group == 1, ] #Las que sean 1
      
      bc <- bioclim(predictores, pres_train)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test, backg_test, bc, predictores)
      
      auc_bc.model <- eval.modesta@auc #auc
      
      cor_bc.model <- eval.modesta@cor #cor
      
      kappa_bc.model <- mean(eval.modesta@kappa) #Kappa

      sensibility_bc.model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_bc.modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSSbc.model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_bc.model,cor_bc.model,kappa_bc.model,sensibility_bc.model,specificity_bc.modelo,TSSbc.model))
}

```


```{r}
# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_bc.model <- matrix(ncol=6,nrow=10) 
      
# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
# for (i in 1:10) { cosites_bc.model[i,] <- fddmx(data,predictors2,backgr)} #Todas las covariables
for (i in 1:10) { cosites_bc.model[i,] <- fddmx(data,predictors2,backgr)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_bc.model) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')
```

```{r}
# Hago la media por columnas que es lo que me interesa y lo guardo
coef_bc.model <- apply(cosites_bc.model, 2, mean)
# write.csv(coef_bc.model,'BIOCLIM/coeficientes_BIOCLIM.csv')
coef_bc.model
```

```{r}
# Predictiva de presencias
ext<-extent(-25,40,30,65) #Extensión de terreno (es la misma que usé para recortar los predictores)

predict.presence.bc.bioclim <- predict(object = bc.model,
                                   x = predictors2,
                                   ext = ext)

# La pinto
plot(predict.presence.bc.bioclim)

# La guardo
# saveRDS(predict.presence.bc.bioclim, "BIOCLIM/Predicciones_BIOCLIM.ascii")
```

# MAXENT

```{r}
# Construyo el modelo
maxent_model <- maxent(predictors2, data,backgr)

plot(maxent_model@presence)
plot(maxent_model)
```


```{r}

fddmx1 <- function(coordenadas, predictores,background){

      group <- kfold(coordenadas, 5)

      pres_train <- coordenadas[group != 1, ] #Las que no sean 1
      pres_test <- coordenadas[group == 1, ] #Las que sean 1
      
      me_m<- maxent(predictores, pres_train,background)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test, backg_test, me_m, predictores)
      
      auc_bc.model <- eval.modesta@auc #auc
      
      cor_bc.model <- eval.modesta@cor #cor
      
      kappa_bc.model <- mean(eval.modesta@kappa) #Kappa

      sensibility_bc.model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_bc.modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSSbc.model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_bc.model,cor_bc.model,kappa_bc.model,sensibility_bc.model,specificity_bc.modelo,TSSbc.model))
}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_maxent_model <- matrix(ncol=6,nrow=10) 
      
# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) { cosites_maxent_model[i,] <- fddmx1(data,predictors2,backgr)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_maxent_model) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_mx.model <- apply(cosites_maxent_model, 2, mean)
coef_mx.model 
# write.csv(coef_mx.model,'MAXENT/coeficientes_MAXENT.csv')
```

```{r}
# Predicciones de presencia
# predict.presence.maxent_model <- dismo::predict(object = maxent_model, 
#                                    x = predictors2, 
#                                    ext = ext) #Todas

predict.presence.maxent_model <- dismo::predict(object = maxent_model, 
                                   x = predictors2, 
                                   ext = ext)

plot(predict.presence.maxent_model)

# Me guardo el modelo predictivo
# saveRDS(predict.presence.maxent_model, "MAXENT/Predicciones_MAXENT.ascii")
```
