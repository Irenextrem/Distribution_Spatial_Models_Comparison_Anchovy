---
title: "Modelos para compilar"
author: "Irene Extremera Serrano"
date: "10/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, warning = FALSE, error = FALSE, message = FALSE, comment = " ")
```

````{r, warning=FALSE, message=FALSE, }
library(sp) #Tabajar con objetos de tipo espacial
library(rgdal) #Para que funcione sdmpredictors
library(carData)
library(car)
library(nlme)
library(gstat)
library(sf)
library(spData)
library(spdep)
library(lattice)
library(survival)
library(Formula)
library(ggplot2)
library(Hmisc)
library(raster) #Para poder trabajar con objetos tipo raster
library(leaflet)
library(GGally)
library(maptools)
library(corrplot)
library(rgeos)
library(maptools) #Cargar mapas
library(dismo) #Para poder trabajar con bioclim
library(sdmpredictors) #Para descargarme las variables ambientales
library(PresenceAbsence)
```

```{r}

# Descargo el mapa del mundo
data(wrld_simpl) #Cargo el mapa del mundo
```


```{r}
# Datos
data <- read.csv('Datos/Anchoas_Aqua.csv',TRUE,",")
data<- data[-1]
```

```{r}
# Predictores
files<-(list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores", full.names=T, pattern=".tif"))#change directory
predictors <- stack(files)
names(predictors) <- c("bathy","chlomean","ppmean","odismean","salinity","tempmean")
plot(predictors)
```

```{r}
# Escalo los valores para que al hacer el análisis todas las variables tengan la misma escala 
predictors2 <- scale(predictors)
round(apply(values(predictors2), 2, summary), 4)

# Cargo la base de datos
sdmdata <- read.csv("Datos/sdmdata.csv")
```


###############################
##### --- Descriptiva --- #####
###############################

```{r}
# Miro la correlación entre variables para identificar qué variables o no incluir.
# La X muestra que no hay correlación significativa.
# La correlación se empieza a plantear el no introducirlaa partir de 0.7.
# Hago modelos con correlación y sin ella para ver cómo ajustan y ver cómo se explica.

matrix<-rcorr(as.matrix(sdmdata[,c(2:10)]), type = "pearson")

# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat<- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], ...)
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

corrplot(matrix$r, type="lower", tl.col = "black",method="number",
         p.mat = matrix$P, sig.level = 0.05)
```

Se puede observar que las correlaciones entre las distintas variables son bastante altas:
- pb (mi variable respuesta) y bathy, 0.53. No es exageradamente alta como otras que vamos a ver pero ahí está.
- Chlomean y odismean con un 0.89, bastante alta.
- Chlomean también correlaciona negativamente con tempmean -0.64. No supera por los pelos el 0.7 pero es ligeramente elevado.
- ppmean tiene una correlación negativa alta con salinidad -0.8 y tempmean -0.88.

A si a primera vista diría que las variables mas indicadas para entrar en el modelo serían: bathy, odismean, salinity y tempmean. 
También podría valorarse cambiar chlomean por odismean.

```{r, warning=FALSE,message=FALSE}
# Paso 2
# Miro la relación entre la variable respuesta y las covariables con el fin de ver si tienen una relación lineal. 
# Este análisis lo necesitaré posteriormente para considerar o no hacer un gam
my_fn <- function(data, mapping, ...){
  p <- ggplot(data = data, mapping = mapping) + 
    geom_point() + 
    geom_smooth(method=loess, fill="red", color="red", ...) +
    geom_smooth(method=lm, fill="blue", color="blue", ...)
  p
}

g = ggpairs(sdmdata, lower = list(continuous = my_fn))
g
```

En este pairs se aprecia lo siguiente:
- No parece que niguna de las variables sea normal incluyendo la variable respuesta. Por lo que habrá que usar un GLMs o alternativas similares.
- La variable respuesta pb (presencias y ausencias) se distribuye como una binomial.

```{r}
# Compruebo si hay o no multicolinealidad entre variables
# El objetivo es quedarse con un conjunto de variables con un VIF menor a 5 y 3.

source("HighstatLib.r") #Función ya hecha
corvif(sdmdata[,c(1:9)])
```

Con respecto al GVIF hay una gran cantidad de variables que superan con creces el valor de 5 a excepción de batimetría que tiene nu GVIF de 2.44.
A priori no voy a eliminar variables a la hora de hacer modelos, sino que iré mirando poco a poco con qué variables se obtiene un mejor ajuste.

##################################
##### --- Ajuste modelos --- #####
##################################

# BIOCLIM

```{r}

# Hago el modelo de BIOCLIM
bc.model <- bioclim(x = predictors2, p = data)
```



```{r}

# FUNCIÓN DEFINITIVA DEFINITIVÍSIMA MILENARIA XTREM
# Esta función sirve para hacer una cross validation y obtener así los distintos índices que me interesan

fddmx <- function(coordenadas, predictores,background){

      group <- kfold(coordenadas, 5)

      pres_train <- coordenadas[group != 1, ] #Las que no sean 1
      pres_test <- coordenadas[group == 1, ] #Las que sean 1
      
      bc <- bioclim(predictores, pres_train)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test, backg_test, bc, predictores)
      
      auc_bc.model <- eval.modesta@auc #auc
      
      cor_bc.model <- eval.modesta@cor #cor
      
      kappa_bc.model <- mean(eval.modesta@kappa) #Kappa

      sensibility_bc.model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_bc.modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSSbc.model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_bc.model,cor_bc.model,kappa_bc.model,sensibility_bc.model,specificity_bc.modelo,TSSbc.model))
}

```


```{r}
# Necesito este objeto con el que he creado la base de datos sdmdata. La semilla es la misma
set.seed(141592) 
backgr <- randomPoints(predictors2, 1000) 

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_bc.model <- matrix(ncol=6,nrow=10) 
      
# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) { cosites_bc.model[i,] <- fddmx(data,predictors2,backgr)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_bc.model) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')
```

```{r}
# Hago la media por columnas que es lo que me interesa y lo guardo
coef_bc.model <- apply(cosites_bc.model, 2, mean)
write.csv(coef_bc.model,'BIOCLIM/coeficientes_BIOCLIM.csv')
coef_bc.model
```

```{r}
# Predictiva de presencias
ext<-extent(-25,40,30,65) #Extensión de terreno (es la misma que usé para recortar los predictores)

predict.presence.bc.bioclim <- predict(object = bc.model, 
                                   x = predictors2, 
                                   ext = ext)

# La pinto
plot(predict.presence.bc.bioclim)

# La guardo
saveRDS(predict.presence.bc.bioclim, "BIOCLIM/Predicciones_BIOCLIM.ascii")
```

En el mapa predictivo se puede ver que  en el Mar del Norte y en la parte de costa Oeste de Gran Bretaña y Francia hay una probabilidad de presencia de hasta el 0.8. Este valor va disminuyendo progresivamente a medida que se aleja de la zona.
Por otro lado, en la costa de España, Norte de Italia, sobre todo en la noreste, y costa africana cercana a la península ibérica la probabilidad de presencia es de 0.4-0.2.





