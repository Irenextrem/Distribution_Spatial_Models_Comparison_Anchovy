---
title: "Modelos (Descriptiva, BIOCLIM, MAXENT, GLM, BRT & RF)"
author: "Irene Extremera Serrano"
date: "11/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, warning = FALSE, error = FALSE, message = FALSE, comment = " ")
```

````{r, warning=FALSE, message=FALSE, echo= FALSE}

library(sp) #Tabajar con objetos de tipo espacial
library(rgdal) #Es necesaria para la librería sdmpredictors
library(carData)
library(car)
library(nlme)
library(gstat)
library(sf)
library(spData)
library(spdep)
library(lattice)
library(survival)
library(Formula)
library(ggplot2) #Para gráficos de las predicciones
library(Hmisc)
library(raster) #Para poder trabajar con objetos tipo raster
library(leaflet)
library(GGally)
library(maptools)
library(corrplot)
library(rgeos)
library(maptools) #Cargar mapas
library(dismo) #Para poder trabajar con BIOCLIM y MAXENT
library(sdmpredictors) #Para descargarme las variables ambientales
library(PresenceAbsence)
library(rJava)
library(randomForest)
library(INLA) #Para trabajar con INLA
library(Matrix)
library(parallel)
library(foreach)
library(dotCall64)
library(grid)
library(spam)
library(fields)
library(randomForest) #Para realizar Random Fores
library(gbm) #Para realizar vosted regression tree
library(TeachingDemos)
library(raster)
library(stars)
library(mgcv)
```

#################################################
########    CARGAR LAS BASES DE DATOS    ########
#################################################

```{r, echo= FALSE}

# Asignamos un directorio de trabajo

setwd("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Rmd")

# MAPA DEL MUNDO

data(wrld_simpl) 

# PRESENCIA DE ANCHOAS
# Descargué la base de datos de AQUAMAPS y eliminé las ubicaciones que no perteneciesen a Atlántico norte mediante la función: identify() y posteriormente quitándolas de la base de datos.
# Otra cosa a realizar fue la identificación de duplicados mediante las siguientes líneas de código:

# dups2 <- duplicated(data[, c("Lon","Lat")]) #Miro si hay duplicados
# sum(dups2) #Veo cuántos duplicados 
# data <- data[!dups2, ] #Verifico si son diferentes antes de eliminarlos.

# Si existiesen duplicados habría que eliminarlos de la base de datos, en este caso no hubo ninguno.
# Después de todo este procedimiento, guardé esa base de datos con presencias únicamente de Atlántico norte.

data <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/Anchoas_Aqua_atln.csv',TRUE,",")


data <- data[,-1] #Le quito al primera que es una columna de índices
colnames(data) <- c('Lon','Lat') #Le doy nombre a las columnas

#Realizo un plot para cerciorarme que todo está en orden 

plot(wrld_simpl, xlim= c(-20,35),ylim=c(43,70), axes=TRUE,col="light yellow", main='Presencias Anchoa')
points(data$Lon, data$Lat, col="blue", pch=20, cex=0.75)
points(data$Lon, data$Lat, col="pink", cex=0.75)

```

```{r, echo=FALSE}

#PREDICTORES de MASPEC y BIO-ORACLE
# A la hora de seleccionar variables nos hemos guiado por la biología de la especie. Por lo que decidimos trabajar con: batimetría, salinidad, oxígeno disuelto, temperatura media superficial, clorofila media y producción primaria media.

# Para descargarlas utilicé las siguientes líneas de código:

# Llamo primero a los rasters por separado. Como se puede observar, batimetría pertenece a MASPEC y el resto a Bio-Oracle.

# bathy<- load_layers(c("MS_bathy_5m"))
# chlomean<- load_layers(c("BO2_chlomean_ss"))
# ppmean<- load_layers(c("BO2_ppmean_ss"))
# tempmean <- load_layers(c("BO2_tempmean_ss"))
# odismean<- load_layers(c("BO2_dissoxmean_ss"))
# salinity <- load_layers(c("BO2_salinitymean_ss"))

# La longitud de bathy y chlomean es diferente por lo que había que igualarlas al resto con la función resample.

# bathy<-resample(bathy,salinity)
# chlomean<-resample(chlomean,salinity)

# Corté los rasters para luego guardarlos y que así me ocupasen menos 

# ext <-extent(-20,35,43,70) #Para Atlántico Norte
# bathy<-crop(bathy,ext)
# chlomean<-crop(chlomean,ext)
# ppmean<-crop(ppmean,ext)
# tempmean<-crop(tempmean,ext)
# odismean<-crop(odismean,ext)
# salinity<-crop(salinity,ext)

# writeRaster(bathy, filename="bathy_atln.tif", format="GTiff", overwrite=TRUE)
# writeRaster(chlomean, filename="chlomean_atln.tif", format="GTiff", overwrite=TRUE)
# writeRaster(ppmean, filename="ppmean_atln.tif", format="GTiff", overwrite=TRUE)
# writeRaster(odismean, filename="odismean_atln.tif", format="GTiff", overwrite=TRUE)
# writeRaster(salinity, filename="salinity_atln.tif", format="GTiff", overwrite=TRUE)
# writeRaster(tempmean, filename="tempmean_atln.tif", format="GTiff", overwrite=TRUE)

```

```{r, echo= FALSE}

# Ahora simplemente pueden cargarse sin necesidad de tener que descargarlos.
# Para que salga bien es muy importante que los predictores estén en una misma carpeta.

files<-(list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/atl", full.names=T, pattern=".tif"))#change directory
predictors <- stack(files)
names(predictors) <- c("bathy","chlomean","ppmean","odismean","salinity","tempmean")
# plot(predictors) #Los pinto

```

```{r,echo= FALSE}

# Miro a ver si hay NAs
# values(predictors) #Los hay y probablemente sean de la parte de la tierra

# Escalo los valores para que al hacer el análisis todas las variables tengan la misma escala 

predictors2 <- scale(predictors)
# round(apply(values(predictors2), 2, summary), 4) #Me cercioro que estén con media en cero

# Para comprobar que todo está igual para que no me dé problemas habría que usar las siguientes funciones:
# crs() #miramos el systema de referencia de las coordenadas #+proj=longlat +datum=WGS84 +no_defs 
# res() #ver resolucion del raster #0.08333333 0.08333333
# yres() ; xres() #ver resolucion del raster

```

El sistema de referencia es el de coordenadas cartográficas y la resolución es de 0.0833º.

#############################################################
##### --- Presencias, Pseudoausencias & Otras cosas --- #####
#############################################################

```{r,echo= FALSE}

# Una vez que se dispone de las presencias y de las variables predictoras el objetivo siguiuente es: 
# 1- La creación de pseudoausencias
# 2- La adjudicación a esos puntos concretos de presencia y de pseudoausencia sus valores ambientales 
# 3- El almacenamiento de esta información en una base de datos.

# PRESENCIAS: 
# Extraigo las coordenadas de presencias y les doy nombre
# coords_pres <- cbind(data$Lon, data$Lat)
# colnames(coords_pres)<-c("x","y")

# La función extract permite extraer los valores de la variable ambiental de las coordenadas donde están las presencias
# presvals <- extract(predictors2, coords_pres)

# Me cercioro de que todo está correcto
# head(presvals)

```

```{r,echo= FALSE}

# PSEUDOAUSENCIAS
# Pongo una semilla para que me aparezcan los puntos en el mismo sitio
# Genero 1000 pseudoausencias en la zona que me interesa

set.seed(141592) 
backgr <- randomPoints(predictors2, 1000) 

# Lo transformo en data.frame para poder trabajar con ellas
# backgr <-as.data.frame(backgr)
# head(backgr) # Miro que todo está bien.

# Extraigo valores de las variables ambientales de las pseudoausencias
# absvals <- extract(predictors2, backgr)

# Me cercioro de que todo está bien
# head(absvals)

```

```{r,echo= FALSE}

# Pinto las pseudoausencias con el fin de ver que efectivamente se han creado bien

# plot(wrld_simpl, xlim= c(-20,35),ylim=c(43,70), axes=TRUE,col="light yellow")
# points(sdmdata$x, sdmdata$y, col="pink", pch=20, cex=0.75)
# identify()

```


```{r, echo= FALSE}

# JUNTAR TODO EN UNA BASE DE DATOS
# Genero un único vector de coordenadas de presencias y pseudoausencias
# coords<-as.data.frame(rbind(coords,backgr))

# Genero un vector con tantas presencias (1) y ausencias (0) haya
# pb <- c(rep(1, nrow(presvals)), rep(0, nrow(absvals)))

# Junto los datos de las variables ambientales de presencia y pseudoausencia con los 0 y 1.
# sdmdata <- data.frame(cbind(pb, rbind(presvals, absvals), coords))
# head(sdmdata)

#Hay que mirar si hay NAs: si son pocos se quitan, pero si son muchos habría que valorar el hacer una imputación de la media de los datos que están cercanos.
# summary(sdmdata) 
# to.remove <- which(!complete.cases(sdmdata))
# sdmdata <- sdmdata[-to.remove,]

# Se vuelve a hacer el summary para cerciorarse de que ya no hay NAs
# summary(sdmdata)

# Se guarda la base de datos
# write.csv(sdmdata,"Datos/sdmdata.csv")

# Se carga la base de datos con todas las variables y presencias
# sdmdata <- read.csv("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/sdmdata.csv")
# 
# Elimino los datos de pseudoausencia que no están en Atlántico Norte
# Elimino todos lo que están por debajo de la latitud 43
# I<-which(sdmdata[,10]<43)
# s1 <- sdmdata[-I,]
# plot(s1$x, s1$y, col="pink", pch=20, cex=0.75)

#Elimino todos los que quedan del Mediterraneo
# w <- which(s1[,9]>0 & s1[,10]<47)
# s2 <- s1[-w,]
# plot(s2$x, s2$y, col="pink", pch=20, cex=0.75)

#Elimino los que están arriba a la derecha
# z <- which(s2[,9]>30)
# s3 <- s2[-z,]
# plot(s3$x, s3$y, col="pink", pch=20, cex=0.75)

# #El ext es de (-20,35,43,70) (POR SI TENGO QUE MIRAR ALGO)
# min(sdmdata[,9]) #-24.875, ESTO ES UNA PSEUDOAUSENCIA
# min(sdmdata[,10]) #30.04167
# max(sdmdata[,9]) #39.95833
# max(sdmdata[,10]) #64.95833
# which(sdmdata[,9]<"-20")


# Se guarda la base de datos
# write.csv(s3,"C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/sdmdata_atln.csv")

# Se carga la base de datos que presenta solo presencias y pseudoausencias de Atlántico Norte
sdmdata <- read.csv("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/sdmdata_atln.csv")


# Dibujo el mapa con los ejes mas grandes para ver si hay algún valor que está fuera de la zona que me interesa
# plot(wrld_simpl, xlim= c(-10,40),ylim=c(36,75), axes=TRUE,col="light yellow")
# points(sdmdata$x, sdmdata$y, col="pink", pch=20, cex=0.75)

```


#############################################################
################## ----- Descriptiva ----- ##################
#############################################################

Una vez obtenida la base datos a punto comienza la descriptiva.

```{r}

# Miro la correlación entre variables para identificar qué variables o no incluir.
# La correlación se empieza a plantear el no introducir la variable partir de 0.7.
# Hacer modelos con correlación y sin ella para ver cómo ajustan y ver cómo se explica (opcional)

matrix<-rcorr(as.matrix(sdmdata[,c(3:8)]), type = "pearson")

# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat<- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], ...)
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

corrplot(matrix$r, type="lower", tl.col = "black",method="number",
         p.mat = matrix$P, sig.level = 0.05)

```

Se puede observar que las correlaciones entre algunas de las variables son bastante altas:

- Chlomean y odismean con un 0.89, bastante alta y positiva.

- ppmean tiene una correlación negativa alta con salinidad -0.81 y tempmean -0.88.

A si a primera vista diría que las variables mas indicadas para entrar en el modelo serían: bathy, odismean, salinity y tempmean. 

A continuación realizo un ggpairs para ver qué tipo de relación hay entre las covariables escaladas y sin escalar.

```{r, echo=FALSE}

# Escaladas

par(mfrow=c(2,1))
attach(sdmdata)
G1<-ggplot(sdmdata, aes(bathy,chlomean) ) +
  geom_point()
G1

G2<-ggplot(sdmdata, aes(bathy,ppmean) ) +
  geom_point()
G2

G3<-ggplot(sdmdata, aes(bathy,salinity) ) +
  geom_point()
G3

G4<-ggplot(sdmdata, aes(bathy,odismean) ) +
  geom_point()
G4


G5<-ggplot(sdmdata, aes(bathy,tempmean) ) +
  geom_point()
G5


G6<-ggplot(sdmdata, aes(ppmean,chlomean) ) +
  geom_point()
G6

G7<-ggplot(sdmdata, aes(ppmean,odismean) ) +
  geom_point()
G7

G8<-ggplot(sdmdata, aes(ppmean,tempmean) ) +
  geom_point()
G8

G9<-ggplot(sdmdata, aes(ppmean,salinity) ) +
  geom_point()
G9

G10<-ggplot(sdmdata, aes(salinity,chlomean) ) +
  geom_point()
G10

G11<-ggplot(sdmdata, aes(salinity,tempmean) ) +
  geom_point()
G11

G12<-ggplot(sdmdata, aes(salinity,odismean) ) +
  geom_point()
G12

G13<-ggplot(sdmdata, aes(odismean,tempmean) ) +
  geom_point()
G13

G14<-ggplot(sdmdata, aes(odismean,chlomean) ) +
  geom_point()
G14

G15<-ggplot(sdmdata, aes(tempmean,chlomean) ) +
  geom_point()
G15

```

Se observa que la forma que tienen de relacionarse las variables entre ellas es bastante extraña en algunos casos. Por ello se valora a continuación realizar estos mismos gráficos con las variables ambientales sin escalar.


```{r}

# SIN ESCALAR
# Para ello hay que preparar una base de datos como la de sdmdata pero con los predictores no escalados

# PRESENCIAS

coords_pres <- cbind(data$Lon, data$Lat)
colnames(coords_pres)<-c("x","y")
presvals_nos <- extract(predictors, coords_pres)

# AUSENCIAS

absvals_nos <- extract(predictors, backgr)

# COORDENADAS

coords_nos<-as.data.frame(rbind(coords_pres,backgr))

# 1 & 0

pb <- c(rep(1, nrow(presvals_nos)), rep(0, nrow(absvals_nos)))

# BASE DE DATOS

sdmdata_nos <- data.frame(cbind(pb, rbind(presvals_nos, absvals_nos), coords_nos))

# NAs

to.remove <- which(!complete.cases(sdmdata_nos))
sdmdata_nos <- sdmdata_nos[-to.remove,]

```


```{r}

#Si ya los tienes descargados y guardados

files<-(list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/atl/Seleccionadas", full.names=T, pattern=".tif"))
predictors <- stack(files)
names(predictors) <- c("bathy","odismean","salinity","tempmean")

# Escalo los valores para que al hacer el análisis todas las variables tengan la misma escala 

predictors3 <- scale(predictors) #Ya he comprobado que tienen su media en cero en otro script

# Pseudoausencias
# Pongo una semilla para que me aparezcan los puntos en el mismo sitio
# Genero 1000 pseudoausencias en la zona que me interesa

files<-(list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/atl", full.names=T, pattern=".tif"))
predictors <- stack(files)
names(predictors) <- c("bathy","chlomean","ppmean","odismean","salinity","tempmean")
predictors2 <- scale(predictors)
set.seed(141592) 
backgr <- randomPoints(predictors2, 1000) 

# Lo transformo en data.frame para poder trabajar con él

backgr <-as.data.frame(backgr) #Incluyo esta linea de código pero estos valores están dentro de sdmdata

# Cargo la base de datos

sdmdata <- read.csv("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/sdmdata_atln.csv")
sdmdata <- sdmdata[,c(-1,-2)]

```

```{r, echo=FALSE}

# Escaladas

par(mfrow=c(2,1))
attach(sdmdata_nos)
G1<-ggplot(sdmdata_nos, aes(bathy,chlomean) ) +
  geom_point()
G1

G2<-ggplot(sdmdata_nos, aes(bathy,ppmean) ) +
  geom_point()
G2

G3<-ggplot(sdmdata_nos, aes(bathy,salinity) ) +
  geom_point()
G3

G4<-ggplot(sdmdata_nos, aes(bathy,odismean) ) +
  geom_point()
G4


G5<-ggplot(sdmdata_nos, aes(bathy,tempmean) ) +
  geom_point()
G5


G6<-ggplot(sdmdata_nos, aes(ppmean,chlomean) ) +
  geom_point()
G6

G7<-ggplot(sdmdata_nos, aes(ppmean,odismean) ) +
  geom_point()
G7

G8<-ggplot(sdmdata_nos, aes(ppmean,tempmean) ) +
  geom_point()
G8

G9<-ggplot(sdmdata_nos, aes(ppmean,salinity) ) +
  geom_point()
G9

G10<-ggplot(sdmdata_nos, aes(salinity,chlomean) ) +
  geom_point()
G10

G11<-ggplot(sdmdata_nos, aes(salinity,tempmean) ) +
  geom_point()
G11

G12<-ggplot(sdmdata_nos, aes(salinity,odismean) ) +
  geom_point()
G12

G13<-ggplot(sdmdata_nos, aes(odismean,tempmean) ) +
  geom_point()
G13

G14<-ggplot(sdmdata_nos, aes(odismean,chlomean) ) +
  geom_point()
G14

G15<-ggplot(sdmdata_nos, aes(tempmean,chlomean) ) +
  geom_point()
G15

```

Al comparar las gráficas en las que se relacionan las variables escaladas y no se comprueba que efectivamente entre ellas tienen una relación un poco extraña. 

Estas relaciones entre las covariables sirve de aliciente para pensar que uno de los modelos a realizar sea un modelo aditivo generalizado (GAM).
Además, cabe mencionar que la variable respuesta se distribuye como una binomial por lo que otro de los modelos a plantear será un modelo lineal generalizado (GLM).

En la linea de selección de variables, a continuación se mirará la multicolinealidad entre ellas mediante el VIF (factor de inflación de la varianza). Para ello se partirá de todas las variables y posteriormente se irán eliminando una a una las que tengan un mayor valor hasta que el grupo quede con valores de VIF menores a 3.

```{r}

# Compruebo si hay o no multicolinealidad entre variables
# El objetivo es quedarse con un conjunto de variables con un VIF menor a 5 y 3.

source("HighstatLib.r") #Función ya hecha
# corvif(sdmdata[,c(2:7)]) #Solo la hago para las que no son covaraibles
# View(sdmdata)
corvif(sdmdata[,c(2,5,6,7)]) #He ido quitando una a una las que tenían un GVIF mas alto, ppmean y chlmean

```

Las variables con las que me quedaré finalmente han sido: batimetría, oxígeno disuelto, temperatura media y salinidad. 

```{r, echo=FALSE}

# Creo una variable predictores que solo incluya a esas cuatro
# Solo uso las covariables seleccionadas

cuatro_pred <- (list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/atl/Seleccionadas", full.names=T, pattern=".tif")) #Cargo bathy que lo he metido en una carpeta aparte
predictors <- stack(cuatro_pred)
names(predictors) <- c("bathy","odismean","salinity","tempmean")
predictors3 <- scale(predictors)

# Elimino esas covariables de la base de datos

# sdmdata_modelos <- sdmdata[,c(-3,-4)]

# # Se guarda la base de datos
# write.csv(sdmdata_modelos,"sdmdata_atln_modelos.csv")

# Se carga la base de datos sin las variables con alta colinealidad
sdmdata <- read.csv("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/sdmdata_atln_modelos.csv")
sdmdata <- sdmdata[,-1]
# Para comprobar que todo está en orden
# plot(wrld_simpl,xlim=c(-20,35),ylim=c(43,70))
# points(sdmdata[,6],sdmdata[,7])

```

##################################
##### --- Ajuste modelos --- #####
##################################

El esquema que voy a intentar seguir en los modelos va a ser el siguiente:

- Ajuste
- Valoración del modelo usando los residuos (Si puede hacerse)
- Predictiva
- Plot
- Validación cruzada
- Índice de Moran para ver si puede meterse la componente espacial


##### --- BIOCLIM --- #####

Primero comenzaré con el modelo mas sencillo, bioclim del paquete dismo.

```{r}

# Hago el modelo de BIOCLIM

bc.model <- bioclim(x = predictors3, p = data)
# bc.model

# Guardo el modelo

saveRDS(bc.model, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/BIOCLIM/bc.model.rds") #Guardo el modelo BIOCLIM

```

Dentro del objeto no hay residuos por lo que no puedo hacer ningún tipo de análisis de los residuos. Por lo que paso directamente a la realización y representación de la predictiva. (trabajando en ello para sacarlos)

```{r}

# Predictiva de presencias
ext <-extent(-20,35,43,70) #Para Atlántico Norte

predict_presence_bc_bioclim <- predict(object = bc.model,
                                   x = predictors3,
                                   ext = ext)

# La pinto
ggplot() +
  geom_raster(data = raster::as.data.frame(predict_presence_bc_bioclim , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='') +
  guides(fill = guide_legend(label.position = "left", label.hjust = 1))

# La guardo
saveRDS(predict_presence_bc_bioclim, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/BIOCLIM/Predicciones_BIOCLIM_Atl.ascii")

```

En el mapa predictivo se puede ver que  en el Mar del Norte está la probabilidad mas alta de presencia, mientras que en la parte de costa Oeste de Gran Bretaña y Francia hay una probabilidad de presencia es ligeramente mas baja. Este valor va disminuyendo progresivamente a medida que se aleja de la zona.

A continuación valoro la calidad predictiva del modelo mediante la media de diez validaciones cruzadas.

```{r}

# FUNCIÓN DEFINITIVA DEFINITIVÍSIMA MILENARIA XTREM para BIOCLIM.
# Esta función sirve para hacer una cross validation y obtener así los distintos índices que me interesan.

fddmx <- function(coordenadas, predictores,background){

      group <- kfold(coordenadas, 5)

      pres_train <- coordenadas[group != 1, ] #Las que no sean 1
      pres_test <- coordenadas[group == 1, ] #Las que sean 1
      
      bc <- bioclim(predictores, pres_train)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test, backg_test, bc, predictores)
      
      auc_model <- eval.modesta@auc #auc
      
      cor_model <- eval.modesta@cor #cor
      
      kappa_model <- mean(eval.modesta@kappa) #Kappa

      sensibility_model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSS_model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_model,cor_model,kappa_model,sensibility_model,specificity_modelo,TSS_model))
}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_bc_model <- matrix(ncol=6,nrow=10) 
      
# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) { cosites_bc_model[i,] <- fddmx(data,predictors3,backgr)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_bc_model) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_bc_model <- apply(cosites_bc_model, 2, mean)
write.csv(coef_bc_model,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/BIOCLIM/coeficientes_BIOCLIM.csv')#Guardo los coeficientes
coef_bc_model

```

```{r}
###### AUTOCORRELACIÓN ESPACIAL #####

# SACAR LOS RESIDUOS
### Paso de raster a data frame
pi<- raster::as.data.frame(predict_presence_bc_bioclim, xy = TRUE)
### Quito NAs
pi <- na.omit(pi)
str(pi)

# Redondeo porque si no lo hago no hay ninguna coincidencia
pi2<-round(pi,digits = 2)
sdmdata_round<-round(sdmdata,digits = 2)

# Miro cuáles coinciden 
x<- round(sdmdata_round[,6],digits = 2)
y<- round(sdmdata_round[,7],digits = 2)

length((which(pi2[,1]==x))*0) #coinciden 105 celdas
length((which(pi2[,2]==y))*0) #coinciden 159 celdas
length((which(pi2[,2]==y & pi2[,1]==x))*0) #Solo coinciden 2
```

```{r}
# Redondeo porque si no lo hago no hay ninguna coincidencia
pi3<-round(pi,digits = 3)
sdmdata_round<-round(sdmdata,digits = 3)

# Miro cuáles coinciden 
x<- round(sdmdata_round[,6],digits = 3)
y<- round(sdmdata_round[,7],digits = 3)

length((which(pi3[,1]==x))*0) #coinciden 105 celdas
length((which(pi3[,2]==y))*0) #coinciden 159 celdas
length((which(pi3[,2]==y & pi3[,1]==x))*0) #Solo coinciden 2
```

```{r}
#Sin redondear
length((which(pi[,1]==sdmdata[,6]))*0) #Sin redondear coinciden menos, 31
length((which(pi[,2]==sdmdata[,7]))*0) #48
length((which(pi[,2]==sdmdata[,7] & pi[,1]==sdmdata[,6]))*0) #Ninguno

```

```{r}
### AUTOCORRELACIÓN ESPACIAL ###
```

FALTARÍA:
- Sacar los residuos
- Calcular el índice de Moran
- Incluir en BIOCLIM la componente espacial de alguna manera (RAC?)
- Predicción
- CV
- Volver a mirar el índice de Moran

##### --- MAXENT --- #####

El siguiente modelo a realizar será MAXENT, que es muy sencillo de realizar computacionalmente pero es difícil de interpretar en cuanto a lo que hace por dentro (caja negra).

```{r}

# Construyo el modelo

maxent_model <- maxent(predictors3, data,backgr)
saveRDS(maxent_model, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/MAXENT/maxent_model_atl.rds")

plot(maxent_model) 

```

En la gráfica Variable Contribution, se está midiendo el porcentaje de cada variable en cuando a cómo es de importante a la hora de ajustar el modelo. Según muestra la gráfica, las variables mas importantes son la batimetría (70%) y la temperatura media superficial (28%). Siendo salinidad la tercera que mas contribuye con un 2% y odismean con un 0%.

Como el modelo MAXENT del paquete dismo no da tampoco los residuos, no puedo hacer un análisis de los mismo, por lo que pasaré a la realización de la predicción.

```{r}

# Predicciones de presencia

predict_presence_maxent_model <- dismo::predict(object = maxent_model, 
                                   x = predictors3, 
                                   ext = ext)
# La pinto
ggplot() +
  geom_raster(data = raster::as.data.frame(predict_presence_maxent_model , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')+

# Me guardo el modelo predictivo
saveRDS(predict_presence_maxent_model, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/MAXENT/Predicciones_MAXENT_alt.ascii")

```

Al igual que mostraba BIOCLIM, hay probabilidad de ocurrencia alrededor de la costa de Gran Bretaña y Francia, solo que aquí bastante mayor. Sin embargo, en este modelo se aprecia que prácticamente en toda la costa europea hay una alta probabilidad de presencia a excepción de en el interior del mar Blanco y la costa este y oeste de Noruega.

```{r}

fddmx1 <- function(coordenadas, predictores,background){

      group <- kfold(coordenadas, 5)

      pres_train <- coordenadas[group != 1, ] #Las que no sean 1
      pres_test <- coordenadas[group == 1, ] #Las que sean 1
      
      me_m<- maxent(predictores, pres_train,background)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test, backg_test, me_m, predictores)
      
      auc_model <- eval.modesta@auc #auc
      
      cor_model <- eval.modesta@cor #cor
      
      kappa_model <- mean(eval.modesta@kappa) #Kappa

      sensibility_model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSS_model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_model,cor_model,kappa_model,sensibility_model,specificity_modelo,TSS_model))
}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_maxent_model <- matrix(ncol=6,nrow=10) 
      
# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) { cosites_maxent_model[i,] <- fddmx1(data,predictors3,backgr)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_maxent_model) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')


# Hago la media por columnas que es lo que me interesa y lo guardo
coef_mx_model <- apply(cosites_maxent_model, 2, mean)
coef_mx_model 
write.csv(coef_mx_model,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/MAXENT/coeficientes_MAXENT_atln.csv')
```

```{r}
########### AUTOCORRELACIÓN ESPACIAL ##########
```

FALTARÍA:
- Sacar los residuos
- Calcular el índice de Moran
- Incluir en BIOCLIM la componente espacial de alguna manera (RAC?)
- Predicción
- CV
- Volver a mirar el índice de Moran

##### --- BOOSTED REGRESSION TREES --- #####

```{r}

# Modelo

brt1 <-  gbm.step(data=sdmdata, gbm.x = c(2,3,4,5), gbm.y = 1, tree.complexity=1, family = "bernoulli",  learning.rate = 0.01)

saveRDS(brt1, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/brt_model.rds")

```
(No es necesario interpretar e incluir la gráfica de holdout deviance en el TFM)

```{r}

# Análisis del modelo
devexpl <- ((brt1$self.statistics$null-brt1$self.statistics$resid)/brt1$self.statistics$null)*100
devexpl #% de deviance explicada por el modelo
summary(brt1) #% de deviance explicada por cada variable

```

44.76% de deviance es explicada por el modelo.

Además. aproximadamente un 72% de la deviance es explicada por batimetría y cerca del 19% por parte de la temperatura media. En menor medida, 9% de lo que queda es explicado por las dos variables que quedan.

```{r}

# Plot de la respuesta funcional de la variable explicativa con respecto a la respuesta 

gbm.plot(brt1, n.plots=4, write.title=FALSE, plot.layout=c(1,4), common.scale=F) 

```

FALTA REALIZARLO CON LAS VARIABLES SIN ESTANDARIZAR Y VER CUÁL ES LA RELACIÓN DE INFLUENCIA QUE HAY

```{r}
# Predicción
pbrt <- predict(predictors3, brt1,type="response", n.trees=brt1$n.trees, shrinkage= 0.01, distribution="bernoulli")

# Representación
ggplot() +
  geom_raster(data = raster::as.data.frame(pbrt , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')

saveRDS(pbrt , "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/Predicciones_brt_Atl.ascii")

```

¿Pero qué está ocurriendo aquí?

```{r, results= "hide" }
# Validación Cruzada
fddmx3 <- function(coordenadas, base_datos,background,variables){

      group <- kfold(coordenadas, 5) #kfold(1:1592, 5)

      pres_train <- base_datos[group != 1, ] #Las que no sean 1
      pres_test <- base_datos[group == 1, ] #Las que sean 1
      
      model <- gbm.step(data=pres_train, gbm.x = variables, gbm.y = 1, tree.complexity=1, family = "bernoulli",  learning.rate = 0.01)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test[pres_test==1,],pres_test[pres_test==0,],model)
      
      auc_modelo.model <- eval.modesta@auc #auc
      
      cor_modelo.model <- eval.modesta@cor #cor
      
      kappa_modelo.model <- mean(eval.modesta@kappa) #Kappa

      sensibility_modelo.model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_modelo.modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSS_modelo.model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_modelo.model,cor_modelo.model,kappa_modelo.model,sensibility_modelo.model,specificity_modelo.modelo,TSS_modelo.model))
}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_brt <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_brt[i,] <- fddmx3(sdmdata[,c(6,7)],sdmdata,backgr,c(2,3,4,5))}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_brt) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_brt_model <- apply(cosites_brt, 2, mean) 

# Hago la media por columnas que es lo que me interesa y lo guardo
write.csv(coef_brt_model,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_brt.csv')
coef_brt <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_brt.csv')
```

```{r}

coef_brt_model

```


```{r}

# CORRELACIÓN ESPACIAL
#Hago la matriz de vecinos para calcular el índice de Moran

nb <- dnearneigh(as.matrix(sdmdata[,c(6,7)]), 1,max(sdmdata[,c(6,7)]));nb 
listw <- nb2listw(nb,style = "S")

```

```{r}

MoranI <- moran.test(residuals(brt1), listw=listw, randomisation=FALSE); MoranI #p valor de 1 indica que Ho no se rechaza, no hay autocorrelación espacial

Moran_MC <- moran.mc(residuals(brt1), listw=listw, nsim=100); Moran_MC #p valor de 0.9901 Ho no se rechaza, lo cual indica que no hay autocorrelación espacial

```


Según el ínidce de Moran no se aprecia autocorrelación espacial, lo cual puede ser debido a que estoy trabajando con un area muy grande.

A pesar de que no se aprecia autocorrelación espacial voy a implementar a continuación un modelo que tenga en cuenta la autocorrelación espacial de los residuos (RAC).


```{r}

########    RAC model to account spatial autoccorrelation  ###################
#Extract residuals from the BRT model and map them
r<- raster(xmn=-20, xmx=35, ymn=43, ymx=70, nrows=324, ncols=660);r #Hago un raster grande
res(r) <‐ 0.083 #Le doy una resolución de 0.083
xy <-cbind(sdmdata$x, sdmdata$y)#Cojo las coordenadas
xy_residuals <-cbind(xy, resid(brt1)) #Uno las coordenadas y los residuos a un mismo objeto
# predictors3

par(mfrow=c(1,2))
r[cellFromXY(r, xy_residuals)] <-xy_residuals[,3] #Doy esos valoes de residuos a esas coordenadas
plot(r,col='red') #Efectivamente me salen residuos
ext <- c(-20,35,43,70) #Extensión a cortar
salinity <- raster("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/RAC/salinity_atln.TIF") #Cargo este raster para poder ajustar el raster r
r <- resample(r,salinity) #Ajusto las dimensiones de r a las de salinity
r<-crop(r,ext);r #Lo corto
# writeRaster(r, filename="RAC_atln.tif", format="GTiff", overwrite=TRUE) #Lo guado en el wd


#Calculate residuals autocovariate
focal_rac_rast <-focal(r, w=matrix(1,3,3), fun = mean,  na.rm = TRUE)

#Extract the values of the focal operation from focal_rac_rest raserfile using the coordinates stored in xy
focal_rac_vect <-extract(focal_rac_rast, xy)
length(focal_rac_vect)

#Add as a column to the data
dd<-cbind(sdmdata, focal_rac_vect)
I <- is.na(dd$focal_rac_vect)
ddd<- dd[!I,]
dim(dd)
dim(ddd)

# RAC Model
brt_RAC <-  gbm.step(data=ddd, gbm.x = c(2,3,4,5,8), gbm.y = 1, tree.complexity=1, family = "bernoulli",  learning.rate = 0.01)
```


```{r}
# Análisis del modelo
devexpl <- ((brt_RAC$self.statistics$null-brt_RAC$self.statistics$resid)/brt_RAC$self.statistics$null)*100
devexpl #% de deviance explicada por el modelo
summary(brt_RAC) #% de deviance explicada por cada variable
```

Se ve muy claramente que la influencia de la variable espacial a la hora de explicar el modelo es abrumadora en comparación a las otras covariables.

```{r}

# Plot de la respuesta funcional de la variable explicativa con respecto a la respuesta

gbm.plot(brt_RAC, n.plots=5, write.title=FALSE, plot.layout=c(1,5), common.scale=F) 

```

```{r}
# Predicción
# Preparo mis predictores
files<-(list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/RAC", full.names=T, pattern=".tif"))
predictors <- stack(files)
names(predictors) <- c("bathy","odismean","focal_rac_vect","salinity","tempmean")

# Escalo los valores para que al hacer el análisis todas las variables tengan la misma escala 

predictors_rac <- scale(predictors) #Ya he comprobado que tienen su media en cero en otro script

pbrt_RAC <- predict(predictors_rac, brt_RAC,type="response", n.trees=brt_RAC$n.trees, shrinkage= 0.01, distribution="bernoulli")

# Representación
ggplot() +
  geom_raster(data = raster::as.data.frame(pbrt_RAC , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')

saveRDS(pbrt_RAC , "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/Predicciones_brt_RAC_Atl.ascii")

```

¿QUÉ LE PASA A ESTE GRÁFICO QUE NO SALE?

```{r, results= "hide" }
# Validación Cruzada
# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_brt_rac <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_brt_rac[i,] <- fddmx3(ddd[,c(6,7)],ddd,backgr,c(2,3,4,5,8))}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_brt_rac) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_brt_model_rac <- apply(cosites_brt_rac, 2, mean) 

# Hago la media por columnas que es lo que me interesa y lo guardo
write.csv(coef_brt_model_rac,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_brt_rac.csv')
coef_brt_rac <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_brt_rac.csv')
coef_brt_rac
```

```{r}
nb_rac <- dnearneigh(as.matrix(ddd[,c(6,7)]), 1,max(ddd[,c(6,7)]));nb_rac 
listw_rac <- nb2listw(nb_rac,style = "S")

MoranI_rac <- moran.test(residuals(brt_RAC), listw=listw_rac, randomisation=FALSE); MoranI_rac #p valor de 0.05, hay autocorrelación espacial aun ¿?

Moran_MC_rac <- moran.mc(residuals(brt_RAC), listw=listw_rac, nsim=100); Moran_MC_rac #p valor de 0.03, hay autocorrelación espacial

```

##### --- RANDOM FOREST --- #####

```{r}

# Modelo
model <- pb ~ bathy+salinity+tempmean+odismean
rf1 <- randomForest(model, sdmdata);rf1

saveRDS(rf1, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/RF_model.rds")

```

Se puede apreciar que el porcentaje de varianza es de 46.36%. Un porcentaje menor en comparación a BRT.

```{r}

varImpPlot(rf1)

```

Es un diagrama que representa lo importante que son las variables a la hora de realizar el Random Forest.

```{r}

# Predicción

pred_rf <- predict(predictors3, rf1,type="response") #Puedo hacer la predicción también

# rf.resid <- rf1$predicted - sdmdata$pb #calculate residual

saveRDS(pred_rf , "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/Predicciones_RF_Atl.ascii")

ggplot() +
  geom_raster(data = raster::as.data.frame(pred_rf , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')
```

El mapa anterior tiene un aspecto diferente al de BRT sin embargo, la pobabilidad de presencia parece suavizarse considerablemente en comparación.

```{r}

# Validación Cruzada
fddmx4 <- function(coordenadas, base_datos ,background,modelo){

      group <- kfold(coordenadas, 5) #kfold(1:1592, 5)

      pres_train <- base_datos[group != 1, ] #Las que no sean 1
      pres_test <- base_datos[group == 1, ] #Las que sean 1
      
      model <- randomForest(modelo, pres_train)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test[pres_test==1,],pres_test[pres_test==0,],model)
      
      auc_modelo.model <- eval.modesta@auc #auc
      
      cor_modelo.model <- eval.modesta@cor #cor
      
      kappa_modelo.model <- mean(eval.modesta@kappa) #Kappa

      sensibility_modelo.model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_modelo.modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSS_modelo.model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_modelo.model,cor_modelo.model,kappa_modelo.model,sensibility_modelo.model,specificity_modelo.modelo,TSS_modelo.model))
}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_rf <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_rf[i,] <- fddmx4(sdmdata[,c(6,7)],sdmdata,backgr,model)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_rf) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_rf_model <- apply(cosites_rf, 2, mean);coef_rf_model 

# Hago la media por columnas que es lo que me interesa y lo guardo
write.csv(coef_rf_model,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_rf.csv')
coef_RF <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_rf.csv')

```

```{r}

####### AUTOCORRELACIÓN ESPACIAL #######
# Saco los residuos
rf.resid <- rf1[["predicted"]] - sdmdata$pb #calculate residual

#Realizo el test de Moran
MoranI_rf <- moran.test(rf.resid, listw=listw, randomisation=FALSE); MoranI_rf #El p valor de 0.0015 me indica que si que hay autocorrelación espacial
Moran_MC_rf <- moran.mc(rf.resid, listw=listw, nsim=100); Moran_MC_rf #p valor de 0.0099  se rechaza Ho, lo cual indica que hay autocorrelación espacial
```

A la vista de que hay autocorrelación espacial entre las observaciones voy a realizar el modelo de random forest que incluya la varaible espacial mediante la metodología utilizada con anterioridad en BRT.

```{r}
attach(ddd)
model_rac <- pb ~ bathy+salinity+tempmean+odismean+focal_rac_vect
rf_rac <- randomForest(model_rac, ddd);rf_rac
```
El porcentaje de varianza explicada por el modelo es bastante alto, de un 86.8%.

```{r}
varImpPlot(rf_rac)
```

Se aprecia que la variable espacial es la que mas explica el porcentaje de deviance explicada seguida de batimetría, salinidad y temperatura superficial media. Siendo oxígeno disuelto la que menos contribuye.

```{r}

# Predicción

pred_rf_rac <- predict(predictors_rac, rf_rac,type="response") #Puedo hacer la predicción también

# rf.resid <- rf1$predicted - sdmdata$pb #calculate residual

saveRDS(pred_rf_rac , "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/Predicciones_RF_rac_Atl.ascii")

ggplot() +
  geom_raster(data = raster::as.data.frame(pred_rf_rac , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')

```

```{r}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_rf_rac <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_rf_rac[i,] <- fddmx4(ddd[,c(6,7)],ddd,backgr,model_rac)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_rf_rac) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_rf_model_rac <- apply(cosites_rf_rac, 2, mean);coef_rf_model_rac 

# Hago la media por columnas que es lo que me interesa y lo guardo
write.csv(coef_rf_model_rac,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_rf_rac.csv')
coef_rf_rac <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/RF y BRT/coeficientes_rf_rac.csv')
```


```{r}
####### AUTOCORRELACIÓN ESPACIAL #######
# Saco los residuos
rf.resid_rac <- rf_rac[["predicted"]] - ddd$pb 

#Realizo el test de Moran
MoranI_rf_rac <- moran.test(rf.resid_rac, listw=listw_rac, randomisation=FALSE); MoranI_rf_rac #El p valor súper pequeño me indica que si que hay autocorrelación espacial
Moran_MC_rf_rac <- moran.mc(rf.resid_rac, listw=listw_rac, nsim=100); Moran_MC_rf_rac #p valor de 0.0099  se rechaza Ho, lo cual indica que hay autocorrelación espacial
```

Tanto en BRT y RF en el momento que meto la variable espacial con RAC los residuos de ese modelo indican que hay autocorrelación espacial, por lo que algo no debe estar funcionando bien.

##### --- MODELO LINEAL GENERALIZADO --- #####

Debido a que la variable respuesta se distribuye como una binomial voy a realizar un GLM introduciendo las covariables de forma aditiva.


```{r}

# GLM
glm1 <- glm(pb ~ bathy + odismean + tempmean + salinity, data=sdmdata, family="binomial") 

saveRDS(glm1, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/GLM_model.rds")

# Resumen del modelo
summary(glm1) #Todas las variables salen significativas

```
Compruebo a continuación si hay colinealidad entre ellas.

```{r}

# Colinealidad

vif(glm1) #No la hay

```

```{r}

# VALORACIÓN DEL MODELO:
# Normalidad y homocedasticidad

par(mfrow=c(2,2))
plot(glm1) #No se ve normalidad ni homocedasticidad en los residuos

```

Los residuos no son normales, obviamente porque la variable respuesta es una binomial.

```{r}

res_m1 <- residuals(glm1,type='deviance')
shapiro.test(res_m1) #No hay normalidad p valor de 2.2e-16
1-pchisq(glm1$deviance, df = glm1$df.residual, lower.tail = F) #0.0168 hay diferencias significativas entre el modelo nulo y el ajustado

```

El shapiro test indica lo que ya se veia en los residuos, que no hay normalidad en ellos.
Con el pchisq de 0.246 se observa que no hay diferencias significativas entre el modelo nulo y el ajustado.

```{r}

# PREDICCIÓN
predm1<-predict(predictors3,glm1,type='response')

saveRDS(predm1, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/Predicciones_glm_Atl.ascii")

ggplot() +
  geom_raster(data = raster::as.data.frame(predm1 , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')

```

En este mapa se aprecia que la probabilidad de presencia es mayor en general en comparación al resto. Parece estar bastante extendida por por la mayor parte de la costa Europea, Mar del Norte y un poco en el Mar Báltico.

```{r}

coords <- as.data.frame(cbind(sdmdata$x,sdmdata$y)) #Extraigo la lat y long de los puntos obs
ppm1<-extract(predm1,coords) #Lo mismo con los valores de probabilidad de los puntos observados
ppm1<-as.data.frame(ppm1) #Paso a data.frame
sdmdata1<-cbind(sdmdata,ppm1) #Lo junto todo a una base de datos
sdmdata1<-na.omit(sdmdata1) #Elimino los NAs
cor(sdmdata1$ppm1,sdmdata1$pb,method="spearman") # 0.518 es la correlación entre lo predicho y lo observado

# plot(glm1$fitted.values, as.vector(unlist(ppm1)), main='Ajustados VS Observados', xlab='Valores Ajustados', ylab='Valores Observados',col=c('blue','green'))
# abline(0,1)

plot(glm1$fitted.values, sdmdata$pb, main='Ajustados VS Observados', xlab='Valores Ajustados', ylab='Valores Observados',col=c('blue','green'))
abline(0,1)

```

La correlación entre lo predicho y observado es del 0.464. Aparte en la gráfica se observa que los valores predichos frente a observados no se ajustan a la recta.


```{r}

# FUNCIÓN DEFINITIVA DEFINITIVÍSIMA MILENARIA XTREM: Funciona para glm.
# Esta función sirve para hacer una cross validation y obtener así los distintos criterios de valoración del modelo que me interesan

fddmx2 <- function(coordenadas, base_datos,background,model){

      group <- kfold(coordenadas, 5) #kfold(1:1592, 5)

      pres_train <- base_datos[group != 1, ] #Las que no sean 1
      pres_test <- base_datos[group == 1, ] #Las que sean 1
      
      modelo <- update(model, data = pres_train)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test[pres_test==1,],pres_test[pres_test==0,],modelo)

      auc_modelo.model <- eval.modesta@auc #auc
      
      cor_modelo.model <- eval.modesta@cor #cor
      
      kappa_modelo.model <- mean(eval.modesta@kappa) #Kappa

      sensibility_modelo.model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_modelo.modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSS_modelo.model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_modelo.model,cor_modelo.model,kappa_modelo.model,sensibility_modelo.model,specificity_modelo.modelo,TSS_modelo.model))
}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_glm <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_glm[i,] <- fddmx2(sdmdata[,c(6,7)],sdmdata,backgr,glm1)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_glm) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_glm_model <- apply(cosites_glm, 2, mean);coef_glm_model 
write.csv(coef_glm_model,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM Frecuentista/coeficientes_glmfrec.csv')
coef_glm <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/coeficientes_glmfrec.csv')

```

```{r}

MoranI <- moran.test(residuals(glm1), listw=listw, randomisation=FALSE); MoranI #p valor de 1 indica que Ho no se rechaza, no hay autocorrelación espacial
Moran_MC <- moran.mc(residuals(glm1), listw=listw, nsim=100); Moran_MC #p valor de 0.99 Ho no se rechaza, lo cual indica que no hay autocorrelación espacial

```

No hay correlación espacial. Lo cual puede ser debido a que el area de estudio es muy grande.

```{r}
#RAC en glm

glm_rac <-  glm(pb ~ bathy + odismean + tempmean + salinity + focal_rac_vect, data=ddd, family="binomial") 

saveRDS(glm_rac, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/GLM_model.rds")

# Resumen del modelo
summary(glm_rac) #Todas las variables salen significativas

```

```{r}

# Colinealidad

vif(glm_rac) #No la hay

```

```{r}

# VALORACIÓN DEL MODELO:
# Normalidad y homocedasticidad

par(mfrow=c(2,2))
plot(glm_rac) #No se ve normalidad ni homocedasticidad en los residuos

```

Los residuos no son normales, obviamente porque la variable respuesta es una binomial.

```{r}

res_glm_rac <- residuals(glm_rac,type='deviance')
shapiro.test(res_glm_rac) #No hay normalidad p valor de 2.2e-16
1-pchisq(glm_rac$deviance, df = glm_rac$df.residual, lower.tail = F) #0 hay diferencias significativas entre el modelo nulo y el ajustado

```

El shapiro test indica lo que ya se veia en los residuos, que no hay normalidad en ellos.
Con el pchisq de 0 se observa que hay diferencias significativas entre el modelo nulo y el ajustado.


```{r}

# PREDICCIÓN
predm_glm_rac<-predict(predictors_rac,glm_rac,type='response')

saveRDS(predm_rlm_rac, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/Predicciones_glm_rac_Atl.ascii")

ggplot() +
  geom_raster(data = raster::as.data.frame(predm_rlm_rac , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')

```

```{r}
# Otra forma de hacerlo
# coords2 <- cbind(ddd$x,ddd$y)
# ppm2<-extract(predm_glm_rac,coords2) #Lo mismo con los valores de probabilidad de los puntos observados
# ppm2<-as.data.frame(ppm2)

plot(glm_rac$fitted.values, ddd$pb, main='Ajustados VS Observados', xlab='Valores Ajustados', ylab='Valores Observados',col=c('blue','green'))
abline(0,1) #Me da error porque las longitudes son diferentes

```


```{r}

# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_glm_rac <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_glm_rac[i,] <- fddmx2(ddd[,c(6,7)],ddd,backgr,glm_rac)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_glm_rac) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_glm_model_rac <- apply(cosites_glm_rac, 2, mean);coef_glm_model_rac 
write.csv(coef_glm_model_rac,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM Frecuentista/coeficientes_glmrac.csv')
coef_glm_rac <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/coeficientes_glmrac.csv')

```

```{r}

MoranI <- moran.test(residuals(glm_rac), listw=listw_rac, randomisation=FALSE); MoranI #p valor de 0.96 indica que Ho no se rechaza, no hay autocorrelación espacial
Moran_MC <- moran.mc(residuals(glm_rac), listw=listw_rac, nsim=100); Moran_MC #p valor de 0.93 Ho no se rechaza, lo cual indica que no hay autocorrelación espacial

```



### --- GAM --- ###

```{r}
# Modelo sin efecto espacial
gam1 <- gam(pb ~ s(salinity)+s(bathy)+s(tempmean)+s(odismean), family = binomial, data =sdmdata) 

saveRDS(gam1, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/gam_model.rds")

#Aunque ponga un gran número de k en cada uno los resultados de deviance explicada y R^2 varían muy poquito.
# De hecho el R^2 baja y la deviance aumenta. Probé con 150 de k para cada uno y de deviance aumentaba en 5 unidades.

# gam_op<- gam(pb ~ s(salinity, k = 150) + s(bathy, k = 150) + s(tempmean, k = 150) + 
#     s(odismean, k = 150), data =sdmdata)


# Valoración de los residuos
par(mfrow=c(2,2))
gam.check(gam1)
# gam.check(gam_op)

# summary(gam_op)
summary(gam1)

```

El $R^2$ es de 0.514 y el porcentaje de deviance explicada es de 45.6%. Saliendo significativas solo bathy y tempmean.

```{r}

#Predictiva

pred_gam<-predict(predictors3,gam1,type='response')

saveRDS(pred_gam, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/Predicciones_gam_Atl.ascii")

#Representación

ggplot() +
  geom_raster(data = raster::as.data.frame(pred_gam , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')


```


```{r}
# Validación cruzada
# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_gam <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_gam[i,] <- fddmx2(sdmdata[,c(6,7)],sdmdata,backgr,gam1)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_gam) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_gam_model <- apply(cosites_gam, 2, mean);coef_gam_model 
write.csv(coef_gam_model,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/coeficientes_gam.csv')
coef_gam <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/coeficientes_gam.csv')

```


```{r}

# Autocorrelación espacial
MoranI <- moran.test(residuals(gam1), listw=listw, randomisation=FALSE); MoranI #p valor de 0.952, no se rechaza H0. No hay autocorrelación espacial.
Moran_MC <- moran.mc(residuals(gam1), listw=listw, nsim=100); Moran_MC #p valor de 0.9208, no se rechaza H0. No hay autocorrelación espacial

```

A pesar de que no se aprecia autocorrelación espacial se va a valorar el modelo incluyendo la componente espacial con un spline bivariante.

```{r}

# Gam con componente espacial introducida como un spline bivariante de dos dimensiones
gam_esp_bis <- gam(pb ~ s(salinity)+s(bathy)+s(tempmean)+s(odismean) + s(x,y), family = binomial, data =sdmdata)

saveRDS(gam1, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/gam_bi_model.rds")

par(mfrow=c(2,2))
gam.check(gam_esp_bis)

summary(gam_esp_bis)

```

El $R^2$ es mayor que el anterior, de 0.533 y el porcentaje de deviance explicada es de 49.1%. Se puede apreciar que la variable espacial sale muy significativa.

```{r}
#Predictiva

pred_gam_bi <- predict(predictors3, gam_esp_bis, type='response') #No funciona porque la componente espacial no está en predictors3
pred_gam_bi <- predict(gam_esp_bis, sdmdata, type='response') #Si funciona pero sale a modo de data frame y luego no se puedehacer el plot

saveRDS(pred_gam, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/Predicciones_gam_bi_Atl.ascii")

#Representación

ggplot() +
  geom_raster(data = raster::as.data.frame(pred_gam_bi , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')
```

```{r}
# Como con la componente espacial introducida como un spline bivariante no se puede hacer pruebo con RAC
gam_rac <- gam(pb ~ s(salinity)+s(bathy)+s(tempmean)+s(odismean) + s(focal_rac_vect), family = binomial, data =ddd)

saveRDS(gam_rac, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/gam_rac.rds")

summary(gam_rac)

# Valoración de los residuos
par(mfrow=c(2,2))
gam.check(gam_rac)

```
El porcentaje de deviance explicada es bastante alto, de hasta un 91,7% t el $R^2$ ajustado también toma valores elevados (0.928). Como significativas salen tempmean, el efecto espacial y batimetría por lo pelos.

```{r}

#Predictiva
#Primero hago la base de datos

pred_gam_rac <-predict(predictors_rac, gam_rac,type='response')

saveRDS(pred_gam_rac, "C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/Predicciones_gam_rac_Atl.ascii")

#Representación

ggplot() +
  geom_raster(data = raster::as.data.frame(pred_gam_rac , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='') #El mapa sigue saliendo raro...

```


```{r}
# Validación cruzada
# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_gam_rac <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_gam_rac[i,] <- fddmx2(ddd[,c(6,7)],ddd,backgr,gam_rac)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_gam_rac) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_gam_model_rac <- apply(cosites_gam_rac, 2, mean);coef_gam_model_rac 
write.csv(coef_gam_model_rac,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/coeficientes_gam.csv')
coef_gam_rac <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GAM/coeficientes_gam.csv')

```


```{r}

# Autocorrelación espacial
MoranI <- moran.test(residuals(gam_rac), listw=listw_rac, randomisation=FALSE); MoranI #p valor de 0.0002, se rechaza H0. Hay autocorrelación espacial.
Moran_MC <- moran.mc(residuals(gam_rac), listw=listw_rac, nsim=100); Moran_MC #p valor de 0.0099, se rechaza H0. Hay autocorrelación espacial

```
###################################################
############# ----- Comparación ----- #############
###################################################

```{r}
# matriz <- matrix(ncol=6,nrow=5,c(coef_bc_model,coef_mx_model,coef_brt_model,coef_brt_model_rac,coef_rf_model,coef_rf_model_rac,coef_glm_model,coef_glm_model_rac,coef_gam_model,coef_gam_model_rac))
# colnames(matriz) <- c("AUC","COR","Kappa","Sensitivity","Specificity","TSS")
# rownames(matriz) <- c("BIOCLIM","MAXENT","BRT","RF","GLM")
# matriz
```
