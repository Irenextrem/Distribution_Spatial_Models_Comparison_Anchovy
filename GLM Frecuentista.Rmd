---
title: "GLM Frecuentista"
author: "Irene Extremera Serrano"
date: "14/1/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, warning = FALSE, error = FALSE, message = FALSE, comment = " ")
```

````{r, warning=FALSE, message=FALSE, include=FALSE }
library(sp) #Tabajar con objetos de tipo espacial
library(rgdal) #Para que funcione sdmpredictors
library(carData)
library(car)
library(nlme)
library(gstat)
library(sf)
library(spData)
library(spdep)
library(lattice)
library(survival)
library(Formula)
library(ggplot2)
library(Hmisc)
library(raster) #Para poder trabajar con objetos tipo raster
library(leaflet)
library(GGally)
library(maptools)
library(corrplot)
library(rgeos)
library(maptools) #Cargar mapas
library(dismo) #Para poder trabajar con bioclim
library(sdmpredictors) #Para descargarme las variables ambientales
library(PresenceAbsence)
library(rJava)
library(randomForest)
library(INLA) #Para trabajar con INLA
library(Matrix)
library(parallel)
library(foreach)
library(dotCall64)
library(grid)
library(spam)
library(fields)
```

```{r,include=FALSE}
# Descargo el mapa del mundo
data(wrld_simpl) #Cargo el mapa del mundo

# Datos
data <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/Anchoas_Aqua_atln.csv',TRUE,",")
data<- data[-1]

# Predictores
files<-(list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/atl/Seleccionadas", full.names=T, pattern=".tif"))
predictors <- stack(files)
names(predictors) <- c("bathy","odismean","salinity","tempmean")

# Escalo los valores para que al hacer el análisis todas las variables tengan la misma escala 
predictors3 <- scale(predictors) #Ya he comprobado que tienen su media en cero en otro script

# Pseudoausencias
# Pongo una semilla para que me aparezcan los puntos en el mismo sitio
# Genero 1000 pseudoausencias en la zona que me interesa
files<-(list.files("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Predictores/atl/Seleccionadas", full.names=T, pattern=".tif"))
predictors <- stack(files)
names(predictors) <- c("bathy","chlomean","ppmean","odismean","salinity","tempmean")
predictors2 <- scale(predictors)
set.seed(141592) 
backgr <- randomPoints(predictors2, 1000) 

# Lo transformo en data.frame para poder trabajar con él
backgr <-as.data.frame(backgr) #Incluyo esta linea de código pero estos valores están dentro de sdmdata


# Cargo la base de datos
sdmdata <- read.csv("C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/Datos/sdmdata_atl.csv")
```


# GLM

Debido a que la variable respuesta se distribuye como una binomial voy a realizar un GLM introduciendo las covariables de forma aditiva.

  
```{r}
# Compruebo que tienen la misma longitud todas las variables
x <- c()
for(i in 1:7){x[i]<-length(sdmdata[,i])}
x #Tienen la misma longitud

# Compruebo que no hay NAs
summary(sdmdata) #No hay
```


```{r}
# GLM
glm1 <- glm(pb ~ bathy + odismean + tempmean + salinity, data=sdmdata, family="binomial") 

# Resumen del modelo
summary(glm1) #Odismean y tempmean me salen como no significativos

```

Salen como no significativas oxígeno disuelto y temperatura media.

```{r}
# Colinealidad
vif(glm1) 
```

El GVIF en todas las variables es menor de 3.

## Valoración del modelo.

```{r}
# Valoración del modelo:
# Normalidad y homocedasticidad
par(mfrow=c(2,2))
plot(glm1) #No se ve normalidad ni homocedasticidad en los residuos
```
Los residuos no son normales, obviamente porque la variable respuesta es una binomial.

```{r}
res_m1 <- residuals(glm1,type='deviance')
shapiro.test(res_m1) #No hay normalidad p valor de 2.2e-16
1-pchisq(glm1$deviance, df = glm1$df.residual, lower.tail = F) #0.246 no hay diferencias significativas entre el modelo nulo y el ajustado
```

El shapiro test indica lo que ya se veia en los residuos, que no hay normalidad en ellos.
Con el pchisq de 0.246 se observa que no hay diferencias significativas entre el modelo nulo y el ajustado

## Predicción del modelo

```{r}
# Es normal que los residuos me salgan así debido a que estoy trabajando con una binomial.
# A continaución voy a realizar alguna predicción
predm1<-predict(predictors3,glm1,type='response')

# La pinto
ggplot() +
  geom_raster(data = raster::as.data.frame(predm1 , xy = TRUE) , aes(x = x, y = y, fill = layer)) +
  coord_equal() +
  labs( x = "", y = "")+theme_minimal()+
  scale_color_brewer(palette = 'YlGnBu')+ labs(fill='')
```

A diferencia de los dos modelos anteriones la probabilidad de presencia es mucho mayor en prácticamente toda la costa y va disminuyendo a medida que se aleja de ella.

### Valoración de la predicción

#### Correlación
```{r}
# Voy a evaluar la predicción del modelo:
coords <- as.data.frame(cbind(sdmdata$x,sdmdata$y)) #Extraigo la lat y long de los puntos obs
ppm1<-extract(predm1,coords) #Lo mismo con los valores de probabilidad de los puntos observados
ppm1<-as.data.frame(ppm1) #Paso a data.frame
sdmdata1<-cbind(sdmdata,ppm1) #Lo junto todo a una base de datos
sdmdata1<-na.omit(sdmdata1) #Elimino los NAs
cor(sdmdata1$ppm1,sdmdata1$pb,method="spearman") # 0.518 es la correlación entre lo predicho y lo observado
```



#### Cross Validation

```{r, eval=FALSE}

# FUNCIÓN DEFINITIVA DEFINITIVÍSIMA MILENARIA XTREM: Funciona para glm.
# Esta función sirve para hacer una cross validation y obtener así los distintos criterios de valoración del modelo que me interesan

fddmx2 <- function(coordenadas, predictores,background,model){

      group <- kfold(coordenadas, 5)

      pres_train <- coordenadas[group != 1, ] #Las que no sean 1
      pres_test <- coordenadas[group == 1, ] #Las que sean 1
      
      modelo <- update(model, data = pres_train)

      group <- kfold(background, 5) #Hago 5 grupos de esos puntos
      backg_train <- background[group != 1, ]
      backg_test <- background[group == 1, ]
      
      eval.modesta <- evaluate(pres_test, backg_test,  modelo, predictores)
      
      auc_modelo.model <- eval.modesta@auc #auc
      
      cor_modelo.model <- eval.modesta@cor #cor
      
      kappa_modelo.model <- mean(eval.modesta@kappa) #Kappa

      sensibility_modelo.model <- mean(eval.modesta@TPR/(eval.modesta@TPR+eval.modesta@FNR)) #Sensibilidad
      
      specificity_modelo.modelo <- mean(eval.modesta@TNR/(eval.modesta@FPR+eval.modesta@TNR)) #Especificidad
      
      TSS_modelo.model <- mean(eval.modesta@TPR+eval.modesta@TNR-1) #TSS
      
      return(c(auc_modelo.model,cor_modelo.model,kappa_modelo.model,sensibility_modelo.model,specificity_modelo.modelo,TSS_modelo.model))
}
```

```{r}
# Hago una matriz para guardar los valores de los coeficientes de las diez iteraciones que me devuelva la función 
cosites_glm <- matrix(ncol=6,nrow=10) 

# Genereo un bucle for de 10 iteraciones que me devuelva 10 valores diferentes de los 6 coeficientes.
for (i in 1:10) {cosites_glm[i,] <- fddmx2(data,predictors3,backgr,glm1)}

# Le doy nombre a las columnas para saber qué coeficientes hay dentro
colnames(cosites_glm) <- c('AUC','COR','Kappa','Sensitivity','Specificity','TSS')

# Hago la media por columnas que es lo que me interesa y lo guardo
coef_glm_model <- apply(cosites_glm, 2, mean);coef_glm_model 
length(sdmdata)
```

NO PUEDO HACER NADA A PARTIR DE AQUÍ PORQUE EL BUCLE FOR ME DA EL SIGUIENTE ERROR: 
Error in model.frame.default(formula = pb ~ salinity, data = pres_train, : variable lengths differ (found for 'salinity')

```{r}
# write.csv(coef_glm.model,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/coeficientes_GLM.csv')
# coef_glm <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/coeficientes_GLM.csv')
```

```{r}
#################SPATIAL CORRELATION#########################
nb <- dnearneigh(as.matrix(coords), 1,max(coords));nb #Hago la matriz de vecinos para calcular el índice de Moran
listw <- nb2listw(nb,style = "S")
```

```{r}
plot(wrld_simpl, xlim=c(-20,35), ylim=c(43,70), axes=TRUE,col="light yellow")
plot(nb, coords, col='red', lwd=2, add=TRUE)
```

```{r}
MoranI <- moran.test(residuals(glm1), listw=listw, randomisation=FALSE); MoranI #p valor de 1 indica que Ho no se rechaza, no hay autocorrelación espacial
Moran_MC <- moran.mc(residuals(glm1), listw=listw, nsim=100); Moran_MC #p valor de 0.99 Ho no se rechaza, lo cual indica que no hay autocorrelación espacial
```

```{r}
moran_pval <-c(MoranI$p.value,Moran_MC$p.value)
write.csv(moran_pval,'C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/moran_GLM_atln.csv')
moran_pval <- read.csv('C:/Users/Irene/Source/Repositorios/TFM-Irene-Extremera/GLM frecuentista/moran_GLM_atln.csv')
```























